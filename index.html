
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiangjun Gao</title>
  
  <meta name="author" content="Xiangjun Gao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <title>Xiangjun Gao (高祥君)'s Homepage</title>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiangjun Gao (高祥君)</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:gaoxiangjun0211@gmail.com">Email</a> &nbsp/&nbsp
  <!--           <a href="data/cv.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?user=M2hq1_UAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/xiangjun_gao">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/gaoxiangjun">GitHub</a> 
                </p>
              <p>I am a master student at <a href="http://www.bit.edu.cn/">Beijing Institute of Technology</a>, advised by Prof. Yunde Jia and Assitant Prof. Yuwei Wu. 
                Prior to that, I received my B.S. from Department of Computer Science in Beijing Institute of Technology in 2020.
              </p>
                Currently, I am an intern at Tiktok working with Research Scientist <a href="https://sites.google.com/site/jshfeng/home"> Jiashi Feng </a> in Fundamental Research Team.
              </p>
              <p>
                In 2021, I was an intern at Microsoft Researcch Asia, working with <a href="http://jlyang.org/"> Dr. Jiaolong Yang </a> and <a href="https://www.microsoft.com/en-us/research/people/xtong/">Dr. Xin Tong</a> in Internet Graphics Group.
              </p>
              <p>
                My research interests include 3D vision, Neural Rendering and Virtual Avatar.
              </p>
              
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="img/me.jpg"><img src="img/me.jpg" style="width:40%;max-width:40%" alt="profile photo" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
              <!-- <p>
                Representative papers are <span class="highlight">highlighted</span>.
                The CVPR is the premier conference in computer vision research community.
                The ICRA and IV are top conferences in the field of robotics and intelligent vehicles.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
<!-- mps-nerf -->
          <tr onmouseout="uv_stop()" onmouseover="uv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='uv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="img/uv_volume.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='img/mps_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function uv_start() {
                  document.getElementById('uv_image').style.opacity = "1";
                }

                function uv_stop() {
                  document.getElementById('uv_image').style.opacity = "0";
                }
                uv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://gaoxiangjun.github.io/mps_nerf/">
                <papertitle>MPS-NeRF: Generalizable 3D Human Rendering from Multiview Images</papertitle>
              </a>
              <br>
              <strong>Xiangjun Gao</strong>, Jiaolong Yang, Jongyoo Kim, Sida Peng, Zicheng Liu, and Xin Tong
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence  <strong>(TPAMI)</strong></em>, 2022
              <br>
              <a href="https://gaoxiangjun.github.io/mps_nerf/">project page</a> /
              <a href="https://arxiv.org/abs/2203.16875">arXiv</a> /
              <!-- <a href="https://fanegg.github.io/UV-Volumes/files/UV_Volumes_Supplementary_Material.pdf">supplementary</a> / -->
              <a href="https://github.com/gaoxiangjun/MPS-NeRF">code</a>
              <p></p>
              <p>This paper deals with a new challenging task - rendering novel views and novel poses for a person unseen in training, 
                using only multiview still images as input without videos. 
                For this task, we propose a simple yet surprisingly effective method to train a generalizable NeRF with multiview images as conditional input. 
                The key ingredient is a dedicated representation combining a canonical NeRF and a volume deformation scheme. 
                <!-- Using a canonical space enables our method to learn shared properties of human and easily generalize to different people. 
                Volume deformation is used to connect the canonical space with input and target images and query image features for radiance and density prediction. 
                We leverage the parametric 3D human model fitted on the input images to derive the deformation, which works quite well in practice when combined with our canonical NeRF. </p> -->
            </td>
          </tr> 


<!-- hanerf -->
          <!-- <tr onmouseout="hanerf_stop()" onmouseover="hanerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hanerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="img/video-teaser_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='img/teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function hanerf_start() {
                  document.getElementById('hanerf_image').style.opacity = "1";
                }

                function hanerf_stop() {
                  document.getElementById('hanerf_image').style.opacity = "0";
                }
                hanerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://rover-xingyu.github.io/Ha-NeRF/">
                <papertitle>Ha-NeRF&#x1F606: Hallucinated Neural Radiance Fields in the Wild</papertitle>
              </a>
              <br>
              <a href="https://rover-xingyu.github.io/">Xingyu Chen</a>,
              <a href="https://qzhang-cv.github.io/">Qi Zhang</a>,
              <a href="https://xiaoyu258.github.io/">Xiaoyu Li</a>,
              <strong>Yue Chen</strong>,
              <a href="https://fanegg.github.io/">Ying Feng</a>,
              <a href="https://xuanwangvc.github.io/">Xuan Wang</a>,
              <a href="https://juewang725.github.io/">Jue Wang</a>
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2022
              <br>
              <a href="https://rover-xingyu.github.io/Ha-NeRF/">project page</a> /
              <a href="https://arxiv.org/pdf/2111.15246.pdf">arXiv</a> /
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Hallucinated_Neural_Radiance_Fields_in_the_Wild_CVPR_2022_paper.pdf">paper</a> /
              <a href="https://rover-xingyu.github.io/Ha-NeRF/files/Ha_NeRF_CVPR_2022_supp.pdf">supplementary</a> /
              <a href="https://github.com/rover-xingyu/Ha-NeRF">code</a>
              <p></p>
              <p>We recover hallucinated neural radiance fields (Ha-NeRF) from a group of tourism images with variable appearance and complex occlusions. Our method can consistently render free-occlusion views which hallucinate different appearances.</p>
            </td>
          </tr>  -->


          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
  
  <!-- fiber -->
          <!-- <tr onmouseout="fiber_stop()" onmouseover="fiber_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fiber_image'>
                  <img src='img/rec.png' width="160">
                </div>
                <img src='img/exp.png' width="160">
              </div>
              <script type="text/javascript">
                function fiber_start() {
                  document.getElementById('fiber_image').style.opacity = "1";
                }
  
                function fiber_stop() {
                  document.getElementById('fiber_image').style.opacity = "0";
                }
                fiber_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://fanegg.github.io/">
                <papertitle>Displacement Field Estimation Using Fiber Bragg Grating Sensors</papertitle>
              </a>
              <br>
              <strong>Yue Chen</strong>,
              <a href="https://scholar.google.com.hk/citations?user=bfOeljkAAAAJ&hl=zh-CN&oi=sra">Hu Sun</a>
              <br>
              <em>Xiamen University Outstanding Undergraduate Thesis Award</em>, 2019
              <br>
              <p></p>
              <p>Deformation monitoring is vital for the flexible wing, morphing aircraft, and other aircraft. Fiber Bragg Grating (FBG) sensing technology, as a new monitoring and sensing technology, has been widely used in aerospace structural health monitoring. This paper studies the structure deformation monitoring for the wing model using the FBG sensing network.</p>
            </td>
          </tr>  -->

<!-- end -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template adapted from this awesome <a href="https://jonbarron.info">Jon Barron</a> website. <br>
          Last updated June 2022.
      </font>
        </p>
        </td>
      </tr>
      </table>
    </td>
    </tr>
  </table>
  </body>
</html>
