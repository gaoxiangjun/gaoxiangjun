
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiangjun Gao</title>
  
  <meta name="author" content="Xiangjun Gao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <title>Xiangjun Gao (高祥君)'s Homepage</title>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiangjun Gao (高祥君)</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:gaoxiangjun0211@gmail.com">Email</a> &nbsp/&nbsp
  <!--           <a href="data/cv.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?user=M2hq1_UAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/xiangjun_gao">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/gaoxiangjun">GitHub</a> 
                </p>
              <p>I am a master student at <a href="http://www.bit.edu.cn/">Beijing Institute of Technology</a>, advised by Prof. Yunde Jia and Assitant Prof. Yuwei Wu. 
                Prior to that, I received my B.S. from Department of Computer Science in Beijing Institute of Technology in 2020.
              </p>
                Currently, I am an intern at Tiktok working with Research Scientist <a href="https://sites.google.com/site/jshfeng/home"> Jiashi Feng </a> in Fundamental Research Team.
              </p>
              <p>
                In 2021, I was an intern at Microsoft Research Asia, working with <a href="http://jlyang.org/"> Dr. Jiaolong Yang </a> and <a href="https://www.microsoft.com/en-us/research/people/xtong/">Dr. Xin Tong</a> in Internet Graphics Group.
              </p>
              <p>
                My research interests include 3D vision, Neural Rendering and Virtual Avatar, especially in Neural Human Rendering and 3D Human Generation.
              </p>
              
            </td>
            <td style="padding:2.5%;width:80%;max-width:80%">
              <a href="img/me.jpg"><img src="img/me.jpg" style="width:40%;max-width:40%" alt="profile photo" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
              <!-- <p>
                Representative papers are <span class="highlight">highlighted</span>.
                The CVPR is the premier conference in computer vision research community.
                The ICRA and IV are top conferences in the field of robotics and intelligent vehicles.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
<!-- mps-nerf -->
          <tr onmouseout="uv_stop()" onmouseover="uv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='uv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="img/uv_volume.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='img/mps_teaser.png' width="160">
              </div>
              <script type="text/javascript">
                function uv_start() {
                  document.getElementById('uv_image').style.opacity = "1";
                }

                function uv_stop() {
                  document.getElementById('uv_image').style.opacity = "0";
                }
                uv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://gaoxiangjun.github.io/mps_nerf/">
                <papertitle>MPS-NeRF: Generalizable 3D Human Rendering from Multiview Images</papertitle>
              </a>
              <br>
              <strong>Xiangjun Gao</strong>, Jiaolong Yang, Jongyoo Kim, Sida Peng, Zicheng Liu, and Xin Tong
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence  <strong>(TPAMI)</strong></em>, 2022
              <br>
              <a href="https://gaoxiangjun.github.io/mps_nerf/">project page</a> /
              <a href="https://arxiv.org/abs/2203.16875">arXiv</a> /
              <!-- <a href="https://fanegg.github.io/UV-Volumes/files/UV_Volumes_Supplementary_Material.pdf">supplementary</a> / -->
              <a href="https://github.com/gaoxiangjun/MPS-NeRF">code</a>
              <p></p>
              <p>This paper deals with a new challenging task - rendering novel views and novel poses for a person unseen in training, 
                using only multiview still images as input without videos. 
                For this task, we propose a simple yet surprisingly effective method to train a generalizable NeRF with multiview images as conditional input. 
                The key ingredient is a dedicated representation combining a canonical NeRF and a volume deformation scheme. 
                <!-- Using a canonical space enables our method to learn shared properties of human and easily generalize to different people. 
                Volume deformation is used to connect the canonical space with input and target images and query image features for radiance and density prediction. 
                We leverage the parametric 3D human model fitted on the input images to derive the deformation, which works quite well in practice when combined with our canonical NeRF. </p> -->
            </td>
          </tr> 

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Education</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
    
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/bit_small.png">
              </td>
              <td width="25%" valign="center">
                MSc in Computer Science @ Beijing Institute of Technology
                <br>
                Sep. 2020 - now
                <br>
                Advisor: Prof.<a href="https://scholar.google.com/citations?user=Sl6TV7gAAAAJ&hl=zh-CN"> Yunde Jia </a> and Assitant Prof. Yuwei Wu
              </td>
            </tr>
      
          <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="img/bit_small.png"></td>
              <td width="75%" valign="center">
                BSc in Computer Science, Xu Elite Class @ Beijing Institute of Technology
                <br>
                Sep. 2016 - Jun. 2020
          <br>
          <!-- GPA: 89.0/100, Ranking 3/81.  -->
          Ranking 3/81.
              </td>
          </tr>
         
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Experience</heading>
              </td>
            </tr>
          </tbody></table>
      <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/microsoft.png">
              </td>
              <td width="75%" valign="center">
                <a>Microsoft Research Asia</a>
                <br>
                Research Intern
                <br>
                Beijing, China
                <br>
                Generalizable Neural Human Rendering with NeRF, transformer, SMPL
                <br>
                Jan, 2021 - Nov, 2021
          <br>
          Advisor: <a href="http://jlyang.org/"> Dr. Jiaolong Yang </a> and <a href="https://www.microsoft.com/en-us/research/people/xtong/">Dr. Xin Tong</a>
          <br>
          Internet Graphics (IG) Group
              </td>
            </tr>
  
      <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="img/tiktok.png"></td>
              <td width="75%" valign="center">
                <a>Tiktok</a>
                <br>
                Research Intern
                <br>
                Singapore (Remote)
                <br>  
                3D Human Generation, Real time Neural Human Rendering and Fast training
                <br>
                Apr, 2022 - Now
          <br>
          Advisor: <a href="https://sites.google.com/site/jshfeng/home"> Dr. Jiashi Feng </a>
                <br>
                Fundamental Research Team
              </td>
            </tr>
                
          </tbody></table>


<!-- end -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          template adapted from this awesome <a href="https://jonbarron.info">Jon Barron</a> website. 
        </p>
        </td>
      </tr>
      </table>
    </td>
    </tr>
  </table>
  </body>
</html>
